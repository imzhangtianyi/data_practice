{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext, HiveContext\n",
    "from pyspark.sql import functions as fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setAppName('hello_world').setMaster('local[*]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pyspark.SparkContext(conf=conf)\n",
    "# sqlContext = HiveContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_rdd = sc.parallelize([\n",
    "        [1, 'cats are cute', 0],\n",
    "        [2, 'dogs are playfull', 0],\n",
    "        [3, 'lions are big', 1],\n",
    "        [4, 'cars are fast', 1]])\n",
    "users_rdd = sc.parallelize([\n",
    "        [0, 'Alice', 20],\n",
    "        [1, 'Bob', 23],\n",
    "        [2, 'Charles', 32]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_d = documents_rdd.toDF(['doc_id', 'text', 'user_id'])\n",
    "df_u = users_rdd.toDF(['user_id', 'name', 'age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- doc_id: long (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- user_id: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_d.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|avg(age)|\n",
      "+--------+\n",
      "|    25.0|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_age_df = df_u.select(fn.avg('age'))\n",
    "user_age_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---+------+-----------------+\n",
      "|user_id|   name|age|doc_id|             text|\n",
      "+-------+-------+---+------+-----------------+\n",
      "|      0|  Alice| 20|     1|    cats are cute|\n",
      "|      0|  Alice| 20|     2|dogs are playfull|\n",
      "|      1|    Bob| 23|     3|    lions are big|\n",
      "|      1|    Bob| 23|     4|    cars are fast|\n",
      "|      2|Charles| 32|  null|             null|\n",
      "+-------+-------+---+------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_all = df_u.join(df_d, on='user_id', how='left')\n",
    "df_all.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "|   name|count(text)|\n",
      "+-------+-----------+\n",
      "|Charles|          0|\n",
      "|    Bob|          2|\n",
      "|  Alice|          2|\n",
      "+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_all.groupby('name').agg(fn.count('text')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---+-----------+\n",
      "|user_id|   name|age|name_length|\n",
      "+-------+-------+---+-----------+\n",
      "|      0|  Alice| 20|          5|\n",
      "|      1|    Bob| 23|          3|\n",
      "|      2|Charles| 32|          7|\n",
      "+-------+-------+---+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_u.withColumn('name_length', fn.length('name')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = Tokenizer().setInputCol('text').setOutputCol('word_tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+-------+---------------------+\n",
      "|doc_id|text             |user_id|word_tokens          |\n",
      "+------+-----------------+-------+---------------------+\n",
      "|1     |cats are cute    |0      |[cats, are, cute]    |\n",
      "|2     |dogs are playfull|0      |[dogs, are, playfull]|\n",
      "|3     |lions are big    |1      |[lions, are, big]    |\n",
      "|4     |cars are fast    |1      |[cars, are, fast]    |\n",
      "+------+-----------------+-------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tk.transform(df_d).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer().setInputCol('word_tokens').setOutputCol('features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+-------+---------------------+-------------------------+\n",
      "|doc_id|text             |user_id|word_tokens          |features                 |\n",
      "+------+-----------------+-------+---------------------+-------------------------+\n",
      "|1     |cats are cute    |0      |[cats, are, cute]    |(9,[0,5,8],[1.0,1.0,1.0])|\n",
      "|2     |dogs are playfull|0      |[dogs, are, playfull]|(9,[0,2,7],[1.0,1.0,1.0])|\n",
      "|3     |lions are big    |1      |[lions, are, big]    |(9,[0,3,6],[1.0,1.0,1.0])|\n",
      "|4     |cars are fast    |1      |[cars, are, fast]    |(9,[0,1,4],[1.0,1.0,1.0])|\n",
      "+------+-----------------+-------+---------------------+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv.fit(tk.transform(df_d)).transform(tk.transform(df_d)).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['are', 'fast', 'playfull', 'big', 'cars', 'cute', 'lions', 'dogs', 'cats']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.fit(tk.transform(df_d)).vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+-------+---------------------+-------------------------+\n",
      "|doc_id|text             |user_id|word_tokens          |features                 |\n",
      "+------+-----------------+-------+---------------------+-------------------------+\n",
      "|1     |cats are cute    |0      |[cats, are, cute]    |(9,[0,1,3],[1.0,1.0,1.0])|\n",
      "|2     |dogs are playfull|0      |[dogs, are, playfull]|(9,[0,2,5],[1.0,1.0,1.0])|\n",
      "|3     |lions are big    |1      |[lions, are, big]    |(9,[0,4,8],[1.0,1.0,1.0])|\n",
      "|4     |cars are fast    |1      |[cars, are, fast]    |(9,[0,6,7],[1.0,1.0,1.0])|\n",
      "+------+-----------------+-------+---------------------+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "\n",
    "pipeline_cv = Pipeline(stages=[tk, cv])\n",
    "pipeline_cv_transformer = pipeline_cv.fit(df_d)\n",
    "pipeline_cv_transformer.transform(df_d).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
